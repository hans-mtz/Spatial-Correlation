---
title: "Bandwidth and Critical Values Selection"
number-sections: true
author: Hans Martinez
date: today
bibliography: biblio.bib
format:
    pdf:
        documentclass: article
        colorlinks: true
        include-in-header: packages.tex
        keep-tex: true
        # resource-path: 
        #     - "../outputs"
        #     - "../figures"
        latex-output-dir: Doc
execute: 
  echo: false
  warning: false
  error: false
---

```{r}
#| label: setup

library(knitr)
library(tidyverse)
library(fixest)
library(mgcv)
# opts_knit$set(
#     echo = FALSE,
#     fig_path()
# )

library(kableExtra)
options(
    knitr.table.format = "latex",
    knitr.kable.NA = "")
setFixest_etable(markdown = TRUE)

load('../R-morgan/morgans_data.Rdata')
prod_dir <- '../outputs/'

```


## Bandwidth and Critical Values Selection


### Data Generating Process

Preliminary results from the simulations with 40 PCs of the 10x10 B-splines, for different bandwidths $h \in \{0.01, 0.02, \dots, 0.09, 0.10\}$. 

Data was generated from the following data generating process (DGP):
$$
\begin{aligned}
    y_l, x_l &\sim (1-\rho)\epsilon_l +\rho \eta_l \\
    \epsilon_l &\sim N(0,1) \\
    \eta_l &\sim \mathcal{G}(\theta)
\end{aligned}
$$ 

$(y_l,x_l,\epsilon_l,\eta_l)$ are associated with observed spatial location $s_l \in \mathbb{R}^2$. $\epsilon$ is a white noise independent of $s_l$. $\eta$ is generated by a Gaussian process with covariance function $cov(s_l,s_{l}')=\exp(-\theta^{-1}||s_l-s_{l}'||)$. The parameter $\rho\in[0,1)$ controls the spatial correlation of observations.

The parameter of the Gaussian process was set as $\theta=\sqrt{2}/10$. Locations $s_l$ were drawn from the uniform Poisson process inside the unit square, two for each observation. I kept using Morgan's locations. I used 500 observations of each variable $(y_l,x_l,s_l)$. 

The regression model used is 

$$
    y_l=\beta x_l + u_l 
$$

because $y_l$ and $x_l$ are independent draws from the same DGP, the true parameter is $\beta=0$. 

### Critical Values and Bandwidth Selection

From the simulated data and the given number of PCs of the 10x10 triangular B-Splines, I estimated $\tau = (\tau_0, \tau_1)$ from the following model:

$$
  \hat\tau = \arg \max \left\{ -\frac{1}{2} \log\det(\Sigma(\tau))-\frac{1}{2}\hat\varepsilon'\Sigma(\tau)^{-1}\hat\varepsilon \right\}
$$

where $\hat\varepsilon_l = y_l - \hat\beta x_l-w'\hat\gamma$. $w$ is the matrix of the PCs of the 10x10 B-Spline. $\Sigma(\tau)=\exp(\tau_0\cdot I_n)\exp(\tau_1\cdot D)$, where $D_{s_l,s_l'}=||s_l - s_l'||$ is the matrix of the euclidean distances between the locations $s_l$ and $s_{l'}$.

After estimating $\hat\tau$, I simulated 1000 times from $\varepsilon_{sim} \sim N(0,\Sigma(\hat\tau))$ and generated $y_{sim }= \beta_{cand} x_l  + w'\hat\gamma + \varepsilon_{sim}$ for each value of $\beta_{cand} = \{-3/\sqrt{n}, -2/\sqrt{n}, \dots, 2/\sqrt{n}, 3/\sqrt{n}\}$, with $n=500$.

I tested the null hypothesis $H_0: \beta = 0$ against the alternative $H_1: \beta \not= 0$ forming the statistic 

$$
t_{sim} = \frac{\hat\beta}{\hat\sigma(h)_{\hat\beta}/\sqrt{n}} .
$$

I estimated $\hat\sigma(h)_{\hat\beta}$ using the kernel HAC estimator with bandwidth $h$ for different values of $h=\{0.02, 0.04, \dots, 0.08, 0.10\}$.

The critical values were selected as the 2.5\% and 97.5\% quantile of the empirical distribution of the $t_{sim}$ statistics when the $\beta_{cand} = 0$. I repeated this process for each value of $h$. In this first exercise, I kept the number of PCs fixed at 40.

For each bandwidth $h$, I estimated the mean power as the average of the probabilities of rejecting the null hypothesis using the critical values described above when testing $H_0: \beta = 0$ for every $\beta_{cand}$. The probability of rejection for each $\beta_{cand}$ is estimated from the empirical distribution of the simulated statistics of that $\beta_{cand}$ and bandwidth.

@tbl-bw-cv-sel shows the results of the simulations. The table shows the bandwidth, the critical values for the statistic, and the mean power of the test for each bandwidth.

This exercise took around `r round(5370.6/60,0)` minutes to run on an intel MacBook Pro with 16GB of RAM. 

```{r}
#| label: tbl-bw-cv-sel
#| tbl-cap: Bandwidth and Critical Values Selection Results. Simulations with 40 PCs of the 10x10 B-splines, for different bandwidths $h=\\{0.02, 0.04, \dots, 0.08, 0.10\\}$. $\beta_{cand} = \\{-3/\sqrt{n}, -2/\sqrt{n}, \dots, 2/\sqrt{n}, 3/\sqrt{n}\\}$. With $n=500$ and 1000 simulations. The critical values are the 2.5\% and 97.5\% quantiles of the empirical distribution of the simulated statistics when testing the null hypothesis $\beta = 0$ when the $\beta_{cand} = 0$. The mean power is the average of the probability of rejecting the null hypothesis using the critical values described above when testing $\beta = 0$ for every $\beta_{cand}$.

# Load the results from the simulations
bw_tbl<-read.csv('../outputs/bw_cv_sel.csv')
# Create a table with the results

bw_tbl %>%
    kable(
        # format = 'latex',
        booktabs = TRUE,
        # caption = 'Bandwidth and Critical Values Selection Results',
        col.names = c('Bandwidth', 'CV Lower', 'CV Upper', 'Mean Power'),
        digits = c(2, 2, 2, 4),
    )

```

